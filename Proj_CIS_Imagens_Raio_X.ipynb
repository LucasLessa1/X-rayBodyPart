{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU48iA-hf04s"
      },
      "source": [
        "# Imports\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdP-BQTpJ_qP"
      },
      "source": [
        "Proj_CIS_Imagens_Raio_X.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90rqqbARBLJu"
      },
      "source": [
        "## Install pydicom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY-thcKqQhmX",
        "outputId": "a68b0806-c5b1-4f45-e102-7574d7f58d61"
      },
      "outputs": [],
      "source": [
        "# #pydicom trata as imagens em formatos DCM, que é tipo de arquivo das imagens \n",
        "# !pip install pydicom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkGTPS7JBNw8"
      },
      "source": [
        "## Import all libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X75kHVXu3C8m"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-01-04 19:43:43.091941: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-01-04 19:43:43.264399: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/lessinha/X-rayBodyPart/lessinha/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2023-01-04 19:43:43.264450: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2023-01-04 19:43:44.276698: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/lessinha/X-rayBodyPart/lessinha/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2023-01-04 19:43:44.276848: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/lessinha/X-rayBodyPart/lessinha/lib/python3.8/site-packages/cv2/../../lib64:\n",
            "2023-01-04 19:43:44.276861: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "# For files e data manipulations\n",
        "import pandas as pd     \n",
        "import os                \n",
        "import zipfile                \n",
        "import shutil            \n",
        "import glob  \n",
        "import gdown            \n",
        "\n",
        "#For math operations           \n",
        "import time               \n",
        "import random               \n",
        "import math                \n",
        "import numpy as np \n",
        "\n",
        "#For plot\n",
        "from matplotlib import pyplot     \n",
        "import matplotlib.pyplot as plt  \n",
        "\n",
        "#For images operations\n",
        "import cv2             \n",
        "import pydicom          \n",
        "# from google.colab.patches import cv2_imshow    \n",
        "from PIL import Image     \n",
        "from numpy import expand_dims  \n",
        "from scipy.io import loadmat \n",
        "\n",
        "#For model  \n",
        "import tensorflow as tf          \n",
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "\n",
        "# import string             \n",
        "# from tqdm import tqdm     \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Eliminating warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbpbpt_RB-xc"
      },
      "source": [
        "## Functions to downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sqf48VqoeCqt"
      },
      "outputs": [],
      "source": [
        "def download(id: str) -> None:      #Download files by link GoogleDrive\n",
        "    url = 'https://drive.google.com/uc?id=' + str(id)\n",
        "    gdown.download(url, output = None, quiet = False)\n",
        "\n",
        "def unzip(path: str) -> None:     #Unzip files .zip\n",
        "    zip = zipfile.ZipFile(path)\n",
        "    zip.extractall()\n",
        "    zip.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Root path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#If running in colab root_path = '/content/'\n",
        "root_path = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEFniMhVgyUh",
        "outputId": "be9a70a7-dbdc-4053-dc99-9049ed5a7ce7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "O arquivo existe.\n"
          ]
        }
      ],
      "source": [
        "# https://drive.google.com/file/d/1ev-r31j8oRzDlKM_toaeADO2psrA_XXm/view?usp=sharing\n",
        "\n",
        "if os.path.isfile(f'{root_path}archive.zip'):\n",
        "    print('O arquivo existe.')\n",
        "    unzip(f'{root_path}archive.zip')    \n",
        "\n",
        "else:\n",
        "    download('1ev-r31j8oRzDlKM_toaeADO2psrA_XXm')\n",
        "    unzip(f'{root_path}archive.zip')    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PpL-tSErjuD6"
      },
      "outputs": [],
      "source": [
        "#leitura dos arquivos originais para obter tanto o dataset de treino quanto o dataset de teste, que servirá de prova real\n",
        "\n",
        "# os.chdir(f'{root_path}/drive/MyDrive/RAIO-X/RAIO-X/archive.zip (Unzipped Files)\")\n",
        "path = os.getcwd() \n",
        "train_df = pd.read_csv(f'{root_path}train.csv')\n",
        "test_df = pd.read_csv(os.path.join(f'{root_path}sample_submission.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "c8qRth9FkA5p",
        "outputId": "025cb7ee-d42c-4997-9739-775527de86a9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SOPInstanceUID</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.10001001190452685542...</td>\n",
              "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.10022667601042710442...</td>\n",
              "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.10024395388921105474...</td>\n",
              "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.10026689165626095651...</td>\n",
              "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.2.826.0.1.3680043.8.498.10035936364561920980...</td>\n",
              "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      SOPInstanceUID  \\\n",
              "0  1.2.826.0.1.3680043.8.498.10001001190452685542...   \n",
              "1  1.2.826.0.1.3680043.8.498.10022667601042710442...   \n",
              "2  1.2.826.0.1.3680043.8.498.10024395388921105474...   \n",
              "3  1.2.826.0.1.3680043.8.498.10026689165626095651...   \n",
              "4  1.2.826.0.1.3680043.8.498.10035936364561920980...   \n",
              "\n",
              "                                              Target  \n",
              "0  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...  \n",
              "1  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...  \n",
              "2  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...  \n",
              "3  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...  \n",
              "4  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd9hejxZkD94"
      },
      "source": [
        "# Check pre-processing Data Frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IQpmWP3kIhQ",
        "outputId": "041e10b8-f9fa-49da-9010-6ea172300e9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns:\n",
            "Index(['SOPInstanceUID', 'Target'], dtype='object') \n",
            "\n",
            "Types in columns:\n",
            "SOPInstanceUID    object\n",
            "Target            object\n",
            "dtype: object \n",
            "\n",
            "Types in info:\n",
            "                                           SOPInstanceUID Target\n",
            "count                                                1738   1738\n",
            "unique                                               1738     41\n",
            "top     1.2.826.0.1.3680043.8.498.10025629581362719970...     3 \n",
            "freq                                                    1    724 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Checks Pandas Dataset format and content properties\n",
        "print(\"Columns:\")\n",
        "print(train_df.columns, \"\\n\")\n",
        "\n",
        "print(\"Types in columns:\")\n",
        "print(train_df.dtypes, \"\\n\")\n",
        "\n",
        "print(\"Types in info:\")\n",
        "print(train_df.describe(), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZWiLKZcDzF8"
      },
      "source": [
        "## Dictionary Bodyparts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31LpuqzMn04N"
      },
      "source": [
        "The bodyparts code was taken of kaggle [The UNIFESP X-Ray Body Part](https://www.kaggle.com/datasets/felipekitamura/unifesp-xray-bodypart-classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YCh3lR7WCsME"
      },
      "outputs": [],
      "source": [
        "bodyparts = {0 : 'Abdomen', 1 :'Ankle', 2 :'Cervical Spine', 3 : 'Chest', 4 :'Clavicles', 5 :'Elbow',\n",
        "             6 :'Feet', 7 : 'Finger', 8 : 'Forearm', 9 : 'Hand', 10 : 'Hip',\n",
        "            11 : 'Knee', 12 : 'Lower Leg', 13 : 'Lumbar Spine', 14 : 'Others', 15 :'Pelvis',\n",
        "            16 :'Shoulder', 17 :'Sinus', 18 : 'Skull', 19 : 'Thigh', 20 :'Thoracic Spine', 21: 'Wrist'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk9Kily5l8fI"
      },
      "source": [
        "## Fixing folders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUN2MLmNKutt"
      },
      "source": [
        "### Class ImageProcessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0Z0LwdkVoI3l"
      },
      "outputs": [],
      "source": [
        "class ImageProcessing():\n",
        "  '''\n",
        "    This class aims to prepare and organize the images, so she creates the masses for each label (organs),\n",
        "    pre-processes the image for Data Augumentation and places it in its respective folder. Furthermore it puts all the images in a single folder as well.\n",
        "\n",
        "    Attributes\n",
        "      ----------\n",
        "      file_List: 2D or 3D array\n",
        "        \n",
        "\n",
        "      Rotation_Range: int\n",
        "          The limit value that the image can rotate.\n",
        "\n",
        "      bright_range: list\n",
        "          The threshold values of image brightness.\n",
        "\n",
        "      folder: string\n",
        "          Folder name of original images. They are divided into train and test\n",
        "\n",
        "      new_Folder: string\n",
        "          Name of the new folder that stays as pre-processed images.\n",
        "        \n",
        "  '''\n",
        "\n",
        "  def __init__(self, folder: str, new_Folder: str) -> None:\n",
        "    # self.file_List = []\n",
        "    self.rotation_Range = 90 \n",
        "    self.bright_Range = [0.2, 1.5]\n",
        "    self.folder = folder                      #This is the folder of the original folder image\n",
        "    self.new_Folder = new_Folder                #This is the new folder\n",
        "\n",
        "\n",
        "  def create_folders(self) -> None:  \n",
        "    '''\n",
        "      This method creates folders for each label.\n",
        "    '''\n",
        "    os.mkdir(f'{root_path}{self.new_Folder}/') \n",
        "    for bodypart in list(bodyparts.values()):\n",
        "      if os.path.isdir(f'{root_path}{self.new_Folder}/{bodypart}') == False:\n",
        "        os.mkdir(f'{root_path}{self.new_Folder}/{bodypart}')\n",
        "      else:  \n",
        "          pass       \n",
        "\n",
        "\n",
        "  def pre_processing_image(self, dicom_image: pydicom.dicomdir.DicomDir) -> Image:\n",
        "    '''\n",
        "    Pre-process the image and return the pre-processed image.\n",
        "    '''\n",
        "    img = dicom_image.pixel_array                \n",
        "    resized_img  = (np.maximum(img,0)/img.max())*255    #It is a important part. This organize and resized image.\n",
        "    im = resized_img.astype(np.uint8)       #Put in 8 bits format\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))    #Equalizer bright\n",
        "    clahe_img = clahe.apply(im)\n",
        "    return Image.fromarray(clahe_img)\n",
        "    \n",
        "\n",
        "  def name_path_image(self, filename: str, df: pd.core.frame.DataFrame, flag: bool, dictionary: dict = {}):\n",
        "    '''\n",
        "    This function takes the image information and returns the correct name. \n",
        "\n",
        "    The parameter flag (bool) is because self.all_image2Folder doesnt need label variable   \n",
        "    '''\n",
        "    var = filename.split(\"/\")               #Split the string path name\n",
        "    var = var[-1]                           #Take the name of the image\n",
        "    if flag:\n",
        "      return True, var[:-6] \n",
        "\n",
        "    row = df.index[df['SOPInstanceUID']==f'{var[:-6]}'].tolist()  #Search the name in DataFrame. This part [:-6] is to remove -c.dcm of the name\n",
        "    target = df['Target'].iloc[row[0]]      #Take the label key\n",
        "    if len(target.strip()) > 2:             #Images with more than one label (Bodyparts) is ignored\n",
        "      return False, False\n",
        "    \n",
        "    label = dictionary.get(int(target)) \n",
        "    return label, var[:-6]   \n",
        "\n",
        "\n",
        "  def file_list_path(self):\n",
        "    file_list = []\n",
        "    for root, dirs, files in os.walk(f'{root_path}{str(self.folder)}'):\n",
        "      for file in files:\n",
        "        file_list.append(os.path.join(root,file))\n",
        "\n",
        "    self.file_list = file_list\n",
        "\n",
        "\n",
        "  def label_image2folder(self, df: pd.core.frame.DataFrame, dictionary: dict) -> None:    #Put each image in a label folder\n",
        "    '''\n",
        "    This method places each image in its respective label (organ).\n",
        "    '''\n",
        "    self.file_list_path()\n",
        "    for filename in self.file_list:\n",
        "      label, var = self.name_path_image(filename, df=df, dictionary=dictionary, flag = False)\n",
        "      if label == False: continue\n",
        "\n",
        "      dicom = pydicom.dcmread(filename)       #Read filename (image.dcm)\n",
        "      image = self.pre_processing_image(dicom_image=dicom)\n",
        "      image.save(os.path.join(f'{root_path}{self.new_Folder}', f'{label}', f'{var}.png'))    #Save image in .png\n",
        "\n",
        "\n",
        "  def all_Images2Folder(self, df: pd.core.frame.DataFrame) -> None:\n",
        "    '''\n",
        "    Puts all images, from all labels, in a single folder.\n",
        "    '''\n",
        "    self.file_list_path()\n",
        "    for filename in self.file_list:\n",
        "      label, var = self.name_path_image(filename, df=df, flag=True)\n",
        "      if label == False: continue\n",
        "      dicom = pydicom.dcmread(filename)\n",
        "      image = self.pre_processing_image(dicom_image=dicom)\n",
        "      image.save(os.path.join(f'{root_path}{self.new_Folder}/', f'{var[:-6]}.png'))\n",
        "\n",
        "    return None\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-kZDDJCKy22"
      },
      "source": [
        "#### Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "v45QZzKw_cTc",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Organize the test images folder\n",
        "name_Folder_Test = \"test_img\"\n",
        "processImageTest = ImageProcessing(folder='test', new_Folder = name_Folder_Test)\n",
        "\n",
        "try:\n",
        "  os.mkdir(f'{root_path}{name_Folder_Test}')\n",
        "  processImageTest.all_Images2Folder(train_df)\n",
        "\n",
        "except:\n",
        "  shutil.rmtree(f'{root_path}{name_Folder_Test}/')\n",
        "  os.mkdir(f'{root_path}{name_Folder_Test}')\n",
        "  processImageTest.all_Images2Folder(train_df)\n",
        "print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "n4V9OW0-PdNf"
      },
      "outputs": [],
      "source": [
        "#Organize the train images folder\n",
        "nameFolderTrain = \"train_img\"\n",
        "processImageTrain = ImageProcessing(folder='train', new_Folder = nameFolderTrain)\n",
        "\n",
        "try:\n",
        "  processImageTrain.create_folders()\n",
        "  #This \"train\" is the name of the original folder of the images\n",
        "  processImageTrain.label_image2folder(train_df, bodyparts)\n",
        "except:\n",
        "  shutil.rmtree(f'{root_path}{nameFolderTrain}/')\n",
        "  processImageTrain.create_folders()\n",
        "  processImageTrain.label_image2folder(train_df, bodyparts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq_6xV1WKaZX"
      },
      "source": [
        "## Data Augumentation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tZSLw4FVK2_N"
      },
      "source": [
        "### Class DataAugumentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "Gsed_3Jp4kdA"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "import keras\n",
        "\n",
        "\n",
        "\n",
        "class DataAugumentation(ImageProcessing):\n",
        "  '''\n",
        "  This class performs data augmentation of images.  \n",
        "  '''\n",
        "\n",
        "  def __init__(\n",
        "      self, \n",
        "      folder: str, \n",
        "      new_folder: str, \n",
        "      folder_img: str\n",
        "  ) -> None:\n",
        "\n",
        "    super().__init__(folder, new_folder)\n",
        "    self.folder_img = folder_img\n",
        "    self.name_image = []\n",
        "\n",
        "\n",
        "  def duplicate_images_name(self, name:list) -> str:\n",
        "    '''\n",
        "    This function is for cases that make augumentation of augumentation. For that reason\n",
        "    this function change the name of image.\n",
        "    '''\n",
        "    dup = [x for i, x in enumerate(self.name_image) if i != self.name_image.index(x)] \n",
        "\n",
        "\n",
        "    #In case of duplicate, it is written in its name that it is a repetition and a case of random duplication\n",
        "    if len(dup) > 0:\n",
        "      equal_dup = \"_repeted_\" + str(random.randint(-9999,9999))\n",
        "    else:\n",
        "      equal_dup = \"\"\n",
        "    return equal_dup\n",
        "\n",
        "\n",
        "  def process_maximum_originals(self, real_qntd:int, qntd:int, folder:str) -> None:\n",
        "    '''\n",
        "    After generating the images with multiples of the original quantity, \n",
        "    it is up to this function to complete the required number \n",
        "    using as many original images as possible.\n",
        "    '''\n",
        "    for i in range(100):\n",
        "      check = real_qntd + real_qntd*i\n",
        "      if check > qntd: \n",
        "        break\n",
        "      multiplier = i\n",
        "      diff_mult = qntd - check\n",
        "    #From each original image we will take x times to approximate the required\n",
        "    exams = [x for x in os.listdir(f'{root_path}{self.folder_img}/{folder}') if x.find(\"copy\") == -1 ]  \n",
        "    self.augment(folder, exams, multiplier) #Here we take by lot the rest that escapes the multiple\n",
        "    \n",
        "    if diff_mult>0:\n",
        "      exams = [x for x in os.listdir(f'{root_path}{self.folder_img}/{folder}') if x.find(\"copy\") == -1 ]\n",
        "      exams = random.choices(exams, k= diff_mult)\n",
        "      self.augment(folder, exams, 1)\n",
        "\n",
        "  def process_imgs(self, qntd: int = 100) -> None:\n",
        "    '''\n",
        "    This method manages the data augmentation process considering the number of images in each label.\n",
        "    '''\n",
        "    for folder in os.listdir(f'{root_path}{self.folder_img}'):\n",
        "      real_qntd = len(os.listdir(f'{root_path}{self.folder_img}/{folder}')) #real_qntd is quantity of exact images\n",
        "      diff = qntd - real_qntd\n",
        "      if qntd > real_qntd: \n",
        "        if real_qntd >= diff:\n",
        "          #exams  is a list of images path sorted\n",
        "          exams = random.choices(os.listdir(f'{root_path}{self.folder_img}/{folder}'), k= diff)    \n",
        "          self.augment(folder, exams, 1)\n",
        "        else:\n",
        "          self.process_maximum_originals(real_qntd=real_qntd, qntd=qntd, folder=folder)\n",
        "\n",
        "  \n",
        "      #If you have more original images than requested, we get rid of the excess images by drawing too            \n",
        "      elif real_qntd > qntd:\n",
        "        diff = (real_qntd-qntd)\n",
        "        sorteados = glob.glob(f'{root_path}{self.folder_img}/{folder}/*')\n",
        "        for s in random.sample(sorteados, diff):\n",
        "          os.remove(s)\n",
        "\n",
        "\n",
        "  def data_generator(self, original_name: str, folder:str) -> keras.preprocessing.image.NumpyArrayIterator:\n",
        "    '''\n",
        "    This function generator a imagem augumentated.\n",
        "    '''\n",
        "    img = load_img(f'{root_path}{self.folder_img}/{folder}/{original_name}')\n",
        "    data = img_to_array(img)\n",
        "    samples = expand_dims(data, 0)\n",
        "    #Call ImageDataGenerator to change the image, for a new image with rotarion, brightness and flip\n",
        "    datagen = ImageDataGenerator(\n",
        "        horizontal_flip=True,\n",
        "        rotation_range=self.rotation_Range,\n",
        "        brightness_range=self.bright_Range\n",
        "    )\n",
        "  \n",
        "    image_gen = datagen.flow(samples, batch_size=1)\n",
        "    # print(type(image_gen))\n",
        "    return image_gen\n",
        "\n",
        "\n",
        "  def augment_unit(\n",
        "      self, \n",
        "      image_generator, \n",
        "      folder: str, \n",
        "      label_duplicate:str, \n",
        "      original_name: str, \n",
        "      cont_original: int, \n",
        "      cont_copy: int\n",
        "  ) -> None:\n",
        "    ''' \n",
        "    This function performs the data augumentation of just one image only.\n",
        "    '''\n",
        "    batch = image_generator.next()\n",
        "    image = batch[0].astype('uint16')\n",
        "    resized_img  = (np.maximum(image,0)/image.max())*255 \n",
        "    im = Image.fromarray(resized_img.astype(np.uint8))\n",
        "    im.save(f'{root_path}{self.folder_img}/{folder}/{original_name[:-4]}_{label_duplicate}_copy_{cont_original}_{cont_copy}.png')\n",
        "  \n",
        "\n",
        "  def augment(self, folder: str, exams: list, limit: int) -> None:\n",
        "    '''\n",
        "    folder = name I gave to the label folder (ex: skull)\n",
        "    exams = list of image files for each label folder\n",
        "    limit = amount of artificial images created from the original\n",
        "    '''\n",
        "    cont1 = -1\n",
        "    for exam in exams: \n",
        "      self.name_image.append(exam)\n",
        "      image_gen = self.data_generator(original_name=exam, folder=folder)\n",
        "      cont1 =+ 1\n",
        "      equal_dup = self.duplicate_images_name(self.name_image)\n",
        "        \n",
        "      for cont in range(limit):\n",
        "        self.augment_unit(\n",
        "          image_generator = image_gen, folder=folder, \n",
        "          label_duplicate=equal_dup, original_name=exam, \n",
        "          cont_original=cont1, cont_copy=cont\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFOWEQokK7Zm"
      },
      "source": [
        "#### Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "UoiUwPBiWc87"
      },
      "outputs": [],
      "source": [
        "#Augumented for Train image\n",
        "AugumentedTrain  =  DataAugumentation(folder='train', new_folder = nameFolderTrain, folder_img = \"train_img\")\n",
        "qntd_for_model = 100\n",
        "AugumentedTrain.process_imgs(qntd=qntd_for_model) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwOf8Y2iK912"
      },
      "source": [
        "## Check images in folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "ZjnXVpK5erpo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hip\n",
            "100\n",
            "Hand\n",
            "100\n",
            "Wrist\n",
            "100\n",
            "Ankle\n",
            "100\n",
            "Chest\n",
            "100\n",
            "Sinus\n",
            "100\n",
            "Feet\n",
            "100\n",
            "Thoracic Spine\n",
            "100\n",
            "Pelvis\n",
            "100\n",
            "Knee\n",
            "100\n",
            "Clavicles\n",
            "100\n",
            "Elbow\n",
            "100\n",
            "Finger\n",
            "100\n",
            "Abdomen\n",
            "100\n",
            "Thigh\n",
            "100\n",
            "Shoulder\n",
            "100\n",
            "Skull\n",
            "100\n",
            "Cervical Spine\n",
            "100\n",
            "Others\n",
            "100\n",
            "Lower Leg\n",
            "100\n",
            "Lumbar Spine\n",
            "100\n",
            "Forearm\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "for files in os.listdir(f'{root_path}train_img'):\n",
        "  print(files)\n",
        "  print(len(os.listdir(f'{root_path}train_img/{files}')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hip\n",
            "Hand\n",
            "Wrist\n",
            "Ankle\n",
            "Chest\n",
            "Sinus\n",
            "Feet\n",
            "Thoracic Spine\n",
            "Pelvis\n",
            "Knee\n",
            "Clavicles\n",
            "Elbow\n",
            "Finger\n",
            "Abdomen\n",
            "Thigh\n",
            "Shoulder\n",
            "Skull\n",
            "Cervical Spine\n",
            "Others\n",
            "Lower Leg\n",
            "Lumbar Spine\n",
            "Forearm\n"
          ]
        }
      ],
      "source": [
        "for folder in os.listdir(f'{root_path}train_img'):\n",
        "    print(folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWFu3okXLE1F"
      },
      "source": [
        "## Select Folders for model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5F7R9ZUMrMO"
      },
      "source": [
        "### Class Select_Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyC4qq5UcHbf"
      },
      "outputs": [],
      "source": [
        "class Select_Folders(): #This folder check with have the quantities is right and put images of apropriate folder\n",
        "  def __init__(self, root: str, qntd: int, mainPath: str ='') -> None:\n",
        "    self.mainPath = mainPath\n",
        "    self.qntdImages = qntd\n",
        "    self.listNames = []\n",
        "    self.flag = []\n",
        "    self.rootPath = root\n",
        "  \n",
        "\n",
        "  def verify(self, folder2verify, order):   #Verify with folder have the right the amount of images \n",
        "    for files in os.listdir(folder2verify):\n",
        "      self.listNames.append([files, len(os.listdir(f'{folder2verify}/{files}')) ])\n",
        "\n",
        "    for i in self.listNames:\n",
        "      if i[1] > self.qntdImages:\n",
        "      #False if you have folders with less than 100 images or less than self.qntdImages\n",
        "      #The flag list stores the value of phalluses, then the name of the label folder and the number of images in it\n",
        "        self.flag.append([False, i[0], i[1]])\n",
        "\n",
        "    if order == \"print\":\n",
        "      print(self.flag)\n",
        "    if order ==\"result\":\n",
        "      flagzinha = False\n",
        "      \n",
        "      for i in zip(self.flag): \n",
        "        if i[0] == True:\n",
        "          print(f\"Error: The folder {i[1]} has {i[2]} Images.\")\n",
        "        else:\n",
        "          flagzinha = True\n",
        "\n",
        "      if flagzinha == False:\n",
        "        print(f\"Every folder has more than {self.qntdImages} Images.\")\n",
        "\n",
        "  def trainFolder(self, path, qntd , bodyparts): \n",
        "    '''\n",
        "    Create folder for the model with specific amount of images (qntd)\n",
        "    '''\n",
        "    try:\n",
        "      os.mkdir(f\"{self.rootPath}{path}\")\n",
        "      # print(self.rootPath)      # print(path)\n",
        "    except:\n",
        "      shutil.rmtree(f\"{self.rootPath}{path}\")\n",
        "      os.mkdir(f\"{self.rootPath}{path}\")\n",
        "\n",
        "    #For each label in text format it is checked if a folder already exists\n",
        "    for part in list(bodyparts.values()):\n",
        "      if os.path.isdir(f\"{self.rootPath}{path}/{part}\") == False:\n",
        "        os.mkdir(f\"{self.rootPath}{path}/{part}\")\n",
        "      #Select 'x' images from a label folder and copy it to imageModel  \n",
        "      # selectImages = random.choices(os.listdir(f'{self.mainPath}/{part}'), k= qntd)\n",
        "      selectImages = os.listdir(f'{self.mainPath}/{part}')\n",
        "      # print(f'{len(selectImages[:qntd])}')\n",
        "      \n",
        "      for image in selectImages[:qntd]:\n",
        "        pathImageModel = f\"{self.rootPath}{path}/{part}/{image}\"\n",
        "        originalPathImages = f'{self.mainPath}/{part}/{image}'\n",
        "        # print(originalPathImages)\n",
        "        # print(pathImageModel)\n",
        "        shutil.copy(originalPathImages, pathImageModel)\n",
        "  def validationFolder(self, path, qntd , bodyparts, qntd_train): \n",
        "    try:\n",
        "      os.mkdir(f\"{self.rootPath}{path}\")\n",
        "      # print(self.rootPath)      # print(path)\n",
        "    except:\n",
        "      shutil.rmtree(f\"{self.rootPath}{path}\")\n",
        "      os.mkdir(f\"{self.rootPath}{path}\")\n",
        "\n",
        "    #For each label in text format it is checked if a folder already exists\n",
        "    for part in list(bodyparts.values()):\n",
        "      if os.path.isdir(f\"{self.rootPath}{path}/{part}\") == False:\n",
        "        os.mkdir(f\"{self.rootPath}{path}/{part}\")\n",
        "        \n",
        "      selectImages = os.listdir(f'{self.mainPath}/{part}')\n",
        "      # print(f'{len(selectImages[qntd_train:])}')\n",
        "      \n",
        "      for image in selectImages[qntd_train:]:\n",
        "        pathImageModel = f\"{self.rootPath}{path}/{part}/{image}\"\n",
        "        originalPathImages = f'{self.mainPath}/{part}/{image}'\n",
        "        # print(originalPathImages)\n",
        "        # print(pathImageModel)\n",
        "        shutil.copy(originalPathImages, pathImageModel)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1IIJfEd0qsa"
      },
      "outputs": [],
      "source": [
        "for files in os.listdir(f'{root_path}train_img'):\n",
        "  x = len(os.listdir(f'{root_path}train_img/{files}'))\n",
        "  if x != qntd_for_model:\n",
        "    print('Some folder has less than 100 images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr9g67ugNLk6"
      },
      "source": [
        "#### Checking class functionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0Sr_i8DwCxT"
      },
      "outputs": [],
      "source": [
        "qntd_images = 60\n",
        "\n",
        "fix_model = Select_Folders(mainPath = f'{root_path}train_img', root = f'{root_path}', qntd = qntd_images)\n",
        "\n",
        "path = \"train_model\"\n",
        "#Organizing the folder for the train_model\n",
        "# 60 images of 100 for train\n",
        "fix_model.trainFolder(path, qntd_images, bodyparts)\n",
        "fix_model.verify(f'{root_path}train_model/' ,'result')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzFANOYn_lzo"
      },
      "outputs": [],
      "source": [
        "qntd_images_val = 40\n",
        "\n",
        "# fix_model = Select_Folders(mainPath = f'{root_path}/train_img\", root = '/content', qntd = qntd_images_val)\n",
        "fix_model = Select_Folders(mainPath = f'{root_path}train_img', root = f'{root_path}', qntd = qntd_images_val)\n",
        "\n",
        "\n",
        "path = \"val_model\"\n",
        "#Organizing the folder for the val_model\n",
        "# 40 images of 100 for train\n",
        "fix_model.validationFolder(path, qntd_images_val, bodyparts, qntd_train = qntd_images)\n",
        "fix_model.verify(f'{root_path}val_model/', 'result')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4RUsOl-NCom"
      },
      "source": [
        "#### Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS05CxHYh7vW"
      },
      "outputs": [],
      "source": [
        "fix2 = Select_Folders(mainPath = f'{root_path}/train_img', root = f'{root_path}' , qntd = qntd_for_model)\n",
        "#Verify if train_img has more than 100 images \n",
        "fix2.verify( f'{root_path}train_img' ,\"result\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6MTXoa1i_w5"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nhuc2rXIj1OB"
      },
      "outputs": [],
      "source": [
        "#Select size\n",
        "batch_size = 32  \n",
        "img_height = 180 \n",
        "img_width = 180\n",
        "\n",
        "train_dir = f'{root_path}train_model'\n",
        "val_dir = f'{root_path}val_model'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MngoN3LFjbrX"
      },
      "outputs": [],
      "source": [
        "# Build a tensorflow dataset to be placed in the Keras library model\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  train_dir,\n",
        "  validation_split=0.2, #Part destined for a validation dataset\n",
        "  subset=\"training\",\n",
        "  seed=123, \n",
        "  image_size=(img_height, img_width), #\"shape\" of file\n",
        "  batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGpU9RawjgLh"
      },
      "outputs": [],
      "source": [
        "# Build a tensorflow dataset to be placed in the Keras library model\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  val_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fU6vecZz-1_X"
      },
      "outputs": [],
      "source": [
        "# for files in os.listdir(f'{root_path}train_img'):\n",
        "#   print(files)\n",
        "#   print(len(os.listdir(f'{root_path}train_img/{files}')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHe_tRFokskR"
      },
      "source": [
        "## Extra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giL20nRqkjmB"
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "#print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fasPiATEkMXp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#print first images (first batch) of the generator\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wwAyrKbkQf7"
      },
      "outputs": [],
      "source": [
        "#Checking \"shape\" - or format\n",
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmVSAVVxMXEk"
      },
      "outputs": [],
      "source": [
        "#Checking \"shape\" - or format\n",
        "for image_batch, labels_batch in val_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTIfFsT5kxeB"
      },
      "source": [
        "## Implementing Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHyNGzaAkvMe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        "# from tensorflow.keras.applications.inception_v3 import InceptionV3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transfer Learning choosen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAELXV2NONpH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import vgg16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SskivR9LbyCA"
      },
      "outputs": [],
      "source": [
        "#This function belongs to Matheus Vieira, current IEEE-CIS Project Director\n",
        "def plot_history(history: keras.callbacks.History) -> None:\n",
        "  #Show model loss and accuracy while training \n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(acc))\n",
        "\n",
        "  plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(23)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1Bi_3immYWq"
      },
      "outputs": [],
      "source": [
        "# vgg16 = keras.applications.vgg16\n",
        "vgg = vgg16.VGG16(input_shape = (img_width, img_height, 3), \n",
        "                       include_top = False, \n",
        "                       weights = 'imagenet')\n",
        "\n",
        "# vgg.summary()\n",
        "# Layer of transfer learning not trainable\n",
        "# vgg.trainable = False\n",
        "for layer in vgg.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "output = vgg.output\n",
        "# three hidden layers\n",
        "# output = keras.layers.GlobalAveragePooling2D()(output)\n",
        "output = keras.layers.Flatten()(output)\n",
        "output = keras.layers.Dense(512, activation='relu')(output)\n",
        "output = keras.layers.Dropout(0.75)(output) \n",
        "output = BatchNormalization()(output)\n",
        "output = keras.layers.Dropout(0.5)(output) \n",
        "# output = keras.layers.Dense(22, activation='relu')(output)\n",
        "# final softmax layer\n",
        "\n",
        "predictions = keras.layers.Dense(len(bodyparts), activation='softmax')(output)\n",
        "\n",
        "# creating the full model:\n",
        "full_model = keras.models.Model(inputs=vgg.input, outputs=predictions)\n",
        "full_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lXhcgoT3iaV"
      },
      "outputs": [],
      "source": [
        "full_model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=RMSprop(lr=1e-4),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvqOMuWvRfjv"
      },
      "outputs": [],
      "source": [
        "! mkdir model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFyDKre31lx4"
      },
      "outputs": [],
      "source": [
        "# Checkpoint\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'model/model_vgg_{qntd_for_model}_1.h5', \n",
        "                                                verbose = 1, \n",
        "                                                save_best = True, \n",
        "                                                save_weights_only = True)\n",
        "\n",
        "# Early stop\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(patience = 4) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q279AbAotZZp"
      },
      "outputs": [],
      "source": [
        "history = full_model.fit(train_ds, \n",
        "                        epochs=50,\n",
        "                        validation_data=val_ds,\n",
        "                        workers=5,\n",
        "                        callbacks = [checkpoint, early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozBphFTcrP5M"
      },
      "outputs": [],
      "source": [
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkGtZC3DrVdK"
      },
      "outputs": [],
      "source": [
        "import pydot\n",
        "import graphviz\n",
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(full_model, show_shapes=True, show_layer_names=True, to_file=f\"model_vgg_{qntd_for_model}_1.png\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "lessinha",
      "language": "python",
      "name": "lessinha"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "0e0140e72d18cbe16a05191a4da26083f9f60642e3f7337d64fa71714a50a226"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
